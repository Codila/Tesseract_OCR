{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Murphy_1.PNG', 'Murphy_2.PNG', 'Murphy_3.PNG', 'Murphy_4.PNG', 'Murphy_5.PNG', 'Murphy_6.PNG', 'Murphy_7.PNG', 'Murphy_8.PNG', 'Murphy_9.PNG', 'Murphy_10.PNG', 'Murphy_11.PNG', 'Murphy_12.PNG', 'Murphy_13.PNG', 'Murphy_14.PNG', 'Murphy_15.PNG', 'Murphy_16.PNG', 'Murphy_17.PNG', 'Murphy_18.PNG', 'Murphy_19.PNG', 'Murphy_20.PNG', 'Murphy_21.PNG', 'Murphy_22.PNG', 'Murphy_23.PNG', 'Murphy_24.PNG', 'Murphy_25.PNG', 'Murphy_26.PNG']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os \n",
    "path=os.listdir(\"png/\")\n",
    "# def nsort(l): \n",
    "#     return sorted(l, key=lambda a:zip(re.split(\"(\\\\d+)\", a)[0::2], map(int, re.split(\"(\\\\d+)\", a)[1::2])))\n",
    "\n",
    "\n",
    "def main(chunk):\n",
    "      return int(chunk) if chunk.isdigit() else chunk\n",
    "def natural_keys(text):\n",
    "       return [  main(element) for element in re.split('_(\\d+)', text) ] # for each element split on each element of a text\n",
    "\n",
    "path.sort(key=natural_keys)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This code executes before main.\n"
     ]
    }
   ],
   "source": [
    "print(\"This code executes before main.\") \n",
    "\n",
    "def functionA():\n",
    "    print(\"Function A\")\n",
    "\n",
    "def functionB():\n",
    "    print(\"Function B\")\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     functionA()\n",
    "#     functionB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.9\n",
      "\n",
      "ott\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "rund\n",
      "\n",
      "Eee\n",
      "a\n",
      "—_ run\n",
      "\n",
      "o\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "Figure 1.21 (a) Misclassification rate vs K in a Knearest neighbor classifier. On the left, where K is\n",
      "small, the model is complex and hence we overfit. On the right, where K is large, the model is simple\n",
      "and we underfit. Dotted blue line: training set (size 200). Solid red line: test set (size 500). (b) Schematic\n",
      "of 5-fold cross validation. Figure generated by knnClassifyDeno,\n",
      "\n",
      "won't have enough data to train on, and we won't have enough data to make a reliable estimate\n",
      "of the future performance.\n",
      "\n",
      "A simple but popular solution to this is to use cross validation (CV). The idea is simple: we\n",
      "split the training data into K folds; then, for each fold k € {1,...,K}, we train on all the\n",
      "folds but the ’th, and test on the ith, in a round-robin fashion, as sketched in Figure 1.21(b).\n",
      "We then compute the error averaged over all the folds, and use this as a proxy for the test error.\n",
      "(Note that each point gets predicted only once, although it will be used is training K—1 times,\n",
      "It is common to use K = 5; this is called 5-fold CV. If we set K = N, then we get a method\n",
      "called leave-one out cross validation, or LOOCY, since in fold é, we train on all the data cases\n",
      "except for i, and then test on i. Exercise 13 asks you to compute the 5-fold CV estimate of the\n",
      "test error vs K, and to compare it to the empirical test error in Figure 1.2i(a).\n",
      "\n",
      "Choosing K‘ for a KNN classifier is a special case of a more general problem known as model\n",
      "selection, where we have to choose between models with different degrees of flexibility. Cross-\n",
      "validation is widely used for solving such problems, although we will discuss other approaches\n",
      "later in the book.\n",
      "\n",
      "   \n",
      "\n",
      "No free lunch theorem\n",
      "\n",
      "All models are wrong, but some models are useful. — George Box (Box and Draper 1987,\n",
      "p424).n\n",
      "\n",
      "Much of machine learning is concemed with devising different models, and different algorithms\n",
      "to fit them. We can use methods such as cross validation to empirically choose the best method\n",
      "for our particular problem. However, there is no single best model that works optimally for all\n",
      "kinds of problems — this is sometimes called the no free lunch theorem (Wolpert 1996). The\n",
      "reason for this is that a set of assumptions that works well in one domain may work poorly in\n",
      "another\n",
      "\n",
      "IL. George Box is a retired statistics professor at the University of Wisconsin.\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import argparse\n",
    "import cv2\n",
    "\n",
    "#os.chdir(\"C:/Program Files (x86)/Tesseract-OCR\") # tesseract must be in the path of the directory \n",
    "for i in range(len(path)):\n",
    "    text = pytesseract.image_to_string(Image.open(\"png/\"+path[i]))\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"1.2.1.2\\n\\nreasonable guess is that blue crescent should be y = 1, since all blue shapes are labeled 1 in the\\ntraining set. The yellow circle is harder to classify, since some yellow things are labeled y = 1\\nand some are labeled y = 0, and some circles are labeled y = 1 and some y = 0. Consequently\\nit is not clear what the right label should be in the case of the yellow circle. Similarly, the\\ncorrect label for the blue arrow is unclear, since although all the previously seen blue things\\nhave a positive label, all the previously seen arrows have a negative label.\\n\\nThe need for probabilistic predictions\\n\\nTo handle ambiguous cases, such as the yellow circle above, it is desirable to return a probability.\\nThe reader is assumed to already have some familiarity with basic concepts in probability. If\\nnot, please consult Chapter 2 for a refresher, if necessary.\\n\\nWe will denote the probability distribution over possible labels, given the input vector x and\\ntraining set D by p(y|x, D). In general, this represents a vector of length C. (If there are just two\\nclasses, it is sufficient to return the single number p(y = 1|x, D), since p(y = 1|x,D) + p(y =\\nO|x,D) = 1) In our notation, we make explicit that the probability is conditional on the test\\ninput x, as well as the training set D, by putting these terms on the right hand side of the\\nconditioning bar |. We are also implicitly conditioning on the form of model that we use to make\\npredictions. When choosing between different models, we will make this assumption explicit by\\nwriting p(y|x,D, M), where M denotes the model. However, if the model is clear from context,\\nwe will drop M from our notation for brevity.\\n\\nGiven a probabilistic output, we can always compute our “best guess” as to the “true label”\\nusing\\n\\n \\n\\na= fs) an\\n\\n \\n\\nThis corresponds to the most probable class label, and is called the mode of the distribution\\n(ylX, D); it is also known as a MAP estimate (MAP stands for maximum a posteriori). Using\\nthe most probable label makes intuitive sense, but we will give a more formal justification for\\nthis procedure in Section 5.7.\\n\\nNow consider a case such as the yellow circle, where p(g|x, D) is far from LO. If we are not\\nvery confident of our answer, it might be better to say “I don't know” instead of returning an\\nanswer that we don't really trust. This is particularly important in domains such as medicine\\nand finance where we may be risk averse, as we explain in Section 5.7.\\n\\nOne interesting application of the “I don’t know” option arises when playing the TV game\\nshow Jeopardy. In this game, contestants have to solve various word puzzles and answer a\\nvariety of trivia questions, but if they answer incorrectly, they lose money. In 2011, IBM unveiled\\na computer system called Watson which beat the top human Jeopardy champion. Watson uses a\\nvariety of interesting techniques (Ferrucci et al. 2010), but the most pertinent one for our present\\ndiscussion is that it contains a module that estimates how confident it is of its answer. The\\nsystem only chooses to “buzz in” its answer if sufficiently confident it is correct.\\n\\nAnother application where estimating uncertainty is important is in online advertising. Google\\nhas a system known as SmartA$s (ad selection system) that predicts the probability you will click\\non an ad based on vour search history and other user and ad-snecific features (Metz 2010). This\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = pytesseract.image_to_string(Image.open(\"png/\"+path[5]))\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
